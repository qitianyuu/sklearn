{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c8bea3a",
   "metadata": {},
   "source": [
    "# L1、L2 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4f7c5c",
   "metadata": {},
   "source": [
    "#### 正则化：凡是可以减少泛化误差，而不减少训练误差的方法都可以称作正则化方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b596fe",
   "metadata": {},
   "source": [
    "### 范数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a400570d",
   "metadata": {},
   "source": [
    "#### L0范数\n",
    "$$||x||_0 = x_i$$\n",
    "\n",
    "即为向量 $x_0$ 中非零元素的个数，例如：\n",
    "\n",
    "$$x = (1,4,0,3,5,9,0)^T\\\\||x||_0 = 5$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664f38cc",
   "metadata": {},
   "source": [
    "#### L1范数\n",
    "$$||x||_1 = \\sum_{i=0}^{n}{|x_i|}$$\n",
    "\n",
    "即为 x 与原点之间的曼哈顿距离，例如：\n",
    "\n",
    "$$x = (1,4,0,3,5,9,0)^T\\\\||x||_1 = 1+4+3+5+9=22$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63c8c6e",
   "metadata": {},
   "source": [
    "#### L2范数\n",
    "$$||x||_2 = \\sqrt{\\sum_{i=0}^{n}{x_i^2}}$$\n",
    "\n",
    "即为 x 与原点之间的欧式距离，例如：\n",
    "\n",
    "$$x = (1,4,0,3,5,9,0)^T\\\\||x||_2 = \\sqrt{1+16+9+25+81}=\\sqrt{132}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6331bb8c",
   "metadata": {},
   "source": [
    "### L1正则化\n",
    "L1 正则化可以看作是对损失函数的惩罚，采用 L1 范数，其本质是为了约束权重 $w$ 的可能取值空间，从而防止原始数据中的误差和噪声被较大的权重放大，从而防止过拟合\n",
    "\n",
    "人为规定参数的范围，让其在给定的范围内优化 loss 函数，达到最小值，抽象成为有约束的优化问题，可以用拉格朗日乘数法求解"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ac9bdf",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{cases}\n",
    "\\min{\\sum_{i=1}^{N}{(W^Tx_i - y_i)^2}}\\\\\n",
    "s.t.||w||_1 - C \\le 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "写出拉格朗日函数:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "L(W,\\lambda) = \\sum_{i=1}^{N}{(W^Tx_i - y_i)^2} + \\lambda \\left(||w||_1 - C \\right)\\\\\n",
    "\\min_{W}\\max_{\\lambda}L(W,\\lambda)\\\\\n",
    "s.t.\\lambda \\ge 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "其中的常数 C 可以通过 $\\lambda$ 进行计算，因此简化为如下：\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "L(W,\\lambda) = \\sum_{i=1}^{N}{(W^Tx_i - y_i)^2} + \\lambda||w||_1 \\\\\n",
    "\\min_{W}\\max_{\\lambda}L(W,\\lambda)\\\\\n",
    "s.t.\\lambda \\ge 0\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcb9a55",
   "metadata": {},
   "source": [
    "L1 正则化后的最优值会有一定的概率落在坐标轴上，意味着有些特征的权重为零，相当于屏蔽了一部分的特征。可以带来稀疏性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83379d24",
   "metadata": {},
   "source": [
    "### L2正则化\n",
    "L2 正则化与 L1 正则化类似，只是将惩罚项换成了 L2 范数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ab2a64",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{cases}\n",
    "\\min{\\sum_{i=1}^{N}{(W^Tx_i - y_i)^2}}\\\\\n",
    "s.t.||w||_2 - C \\le 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "写出拉格朗日函数:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "L(W,\\lambda) = \\sum_{i=1}^{N}{(W^Tx_i - y_i)^2} + \\lambda \\left(||w||_2 - C \\right)\\\\\n",
    "\\min_{W}\\max_{\\lambda}L(W,\\lambda)\\\\\n",
    "s.t.\\lambda \\ge 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "其中的常数 C 可以通过 $\\lambda$ 进行计算，因此简化为如下：\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "L(W,\\lambda) = \\sum_{i=1}^{N}{(W^Tx_i - y_i)^2} + \\lambda||w||_2 \\\\\n",
    "\\min_{W}\\max_{\\lambda}L(W,\\lambda)\\\\\n",
    "s.t.\\lambda \\ge 0\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433150db",
   "metadata": {},
   "source": [
    "L2 正则化后的最优值不会落在坐标轴上，意味着所有的特征的权重都不可能为零，但是可能无穷小。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
